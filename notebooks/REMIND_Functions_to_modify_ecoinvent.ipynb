{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%run initialize_notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constructive_geometries import Geomatcher\n",
    "from wurst import *\n",
    "from wurst.ecoinvent.electricity_markets import *\n",
    "from wurst.searching import *\n",
    "from wurst.ecoinvent.filters import *\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to clean up Wurst import and additional technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_unset_technosphere_and_production_exchange_locations(db, matching_fields=('name', 'unit')):\n",
    "    for ds in db:\n",
    "        for exc in ds['exchanges']:\n",
    "            if exc['type'] == 'production' and exc.get('location') is None:\n",
    "                exc['location'] = ds['location']                \n",
    "            elif exc['type'] == 'technosphere' and exc.get('location') is None:\n",
    "                locs = find_location_given_lookup_dict(db, \n",
    "                                                       {k: exc.get(k) for k in matching_fields})\n",
    "                if len(locs) == 1:\n",
    "                    exc['location'] = locs[0]\n",
    "                else:\n",
    "                    print(\"No unique location found for exchange:\\n{}\\nFound: {}\".format(\n",
    "                        pprint.pformat(exc), locs\n",
    "                    ))\n",
    "                        \n",
    "def find_location_given_lookup_dict(db, lookup_dict):\n",
    "    return [x['location'] for x in get_many(db, *[equals(k, v) for k, v in lookup_dict.items()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exists = lambda x: {k: v for k, v in x.items() if v is not None}\n",
    "\n",
    "def remove_nones(db):\n",
    "    for ds in db:\n",
    "        ds['exchanges'] = [exists(exc) for exc in ds['exchanges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_location_for_additional_datasets(db):\n",
    "        \"\"\" This function is needed because the wurst function relink_technosphere exchanges needs global datasets if if can't find a regional one.\"\"\"    \n",
    "        non_ecoinvent_datasets = [x['name'] for x in db  if x['database'] not in ['ecoinvent', 'ecoinvent_unchanged']]\n",
    "        ecoinvent_datasets = [x['name'] for x in db  if x['database'] not in ['ecoinvent', 'ecoinvent_unchanged']]\n",
    "\n",
    "        for ds in [x for x in db if x['database'] in ['Carma CCS', 'CSP']]:\n",
    "            print('Dataset: ',ds['name'], ds['location'], ' Changing to Global')\n",
    "            ds['location'] = 'GLO'\n",
    "            for exc in [x for x in ds['exchanges'] if x['type'] != 'biosphere']:\n",
    "                if exc['name'] in non_ecoinvent_datasets:\n",
    "                    if exc['name'] in ecoinvent_datasets and exc['location'] != 'GLO': print ('Ecoinvent exchange: ',exc['name'], exc['location'])\n",
    "                    else: \n",
    "                        print('Exchange: ',exc['name'], exc['location'], 'Changing to Global')\n",
    "                        exc['location'] = 'GLO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region and location mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these locations aren't found correctly by the constructive geometries library - we correct them here:\n",
    "fix_names= {#'CSG' : 'CN-CSG',\n",
    "            #'SGCC': 'CN-SGCC',\n",
    "             \n",
    "             #'RFC' : 'US-RFC',\n",
    "             #'SERC' : 'US-SERC',\n",
    "             #'TRE': 'US-TRE',\n",
    "             #'ASCC': 'US-ASCC',\n",
    "             #'HICC': 'US-HICC',\n",
    "             #'FRCC': 'US-FRCC',\n",
    "             #'SPP' : 'US-SPP',\n",
    "             #'MRO, US only' : 'US-MRO', \n",
    "             #'NPCC, US only': 'US-NPCC', \n",
    "             #'WECC, US only': 'US-WECC',\n",
    "             \n",
    "             'IAI Area, Africa':'IAI Area 1, Africa',\n",
    "             'IAI Area, South America':'IAI Area 3, South America', \n",
    "             'IAI Area, Asia, without China and GCC':'IAI Area 4&5, without China', \n",
    "             'IAI Area, North America, without Quebec':'IAI Area 2, without Quebec',\n",
    "             'IAI Area, Gulf Cooperation Council':'IAI Area 8, Gulf'\n",
    "            }\n",
    "\n",
    "fix_names_back = {v:k for k,v in fix_names.items()}\n",
    "\n",
    "\n",
    "def rename_locations(db, name_dict):\n",
    "    for ds in db:\n",
    "        if ds['location'] in name_dict:\n",
    "            ds['location'] = name_dict[ds['location']]\n",
    "\n",
    "        for exc in technosphere(ds):\n",
    "            if exc['location'] in name_dict:\n",
    "                exc['location'] = name_dict[exc['location']]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rauner\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\constructive_geometries\\cg.py:77: FionaDeprecationWarning: Use fiona.Env() instead.\n",
      "  with fiona.drivers():\n",
      "C:\\Users\\rauner\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\country_converter\\country_converter.py:412: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  for str_col in must_be_string})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geomatcher: Used 'AU' for 'AUS'\n",
      "Geomatcher: Used 'CA' for 'CAN'\n",
      "Geomatcher: Used 'HM' for 'HMD'\n",
      "Geomatcher: Used 'NZ' for 'NZL'\n",
      "Geomatcher: Used 'PM' for 'SPM'\n",
      "Geomatcher: Used 'CN' for 'CHN'\n",
      "Geomatcher: Used 'HK' for 'HKG'\n",
      "Geomatcher: Used 'MO' for 'MAC'\n",
      "Geomatcher: Used 'TW' for 'TWN'\n",
      "Geomatcher: Used 'AX' for 'ALA'\n",
      "Geomatcher: Used 'AT' for 'AUT'\n",
      "Geomatcher: Used 'BE' for 'BEL'\n",
      "Geomatcher: Used 'BG' for 'BGR'\n",
      "Geomatcher: Used 'CY' for 'CYP'\n",
      "Geomatcher: Used 'CZ' for 'CZE'\n",
      "Geomatcher: Used 'DE' for 'DEU'\n",
      "Geomatcher: Used 'DK' for 'DNK'\n",
      "Geomatcher: Used 'ES' for 'ESP'\n",
      "Geomatcher: Used 'EE' for 'EST'\n",
      "Geomatcher: Used 'FI' for 'FIN'\n",
      "Geomatcher: Used 'FR' for 'FRA'\n",
      "Geomatcher: Used 'FO' for 'FRO'\n",
      "Geomatcher: Used 'GB' for 'GBR'\n",
      "Geomatcher: Used 'GI' for 'GIB'\n",
      "Geomatcher: Used 'GR' for 'GRC'\n",
      "Geomatcher: Used 'HR' for 'HRV'\n",
      "Geomatcher: Used 'HU' for 'HUN'\n",
      "Geomatcher: Used 'IM' for 'IMN'\n",
      "Geomatcher: Used 'IE' for 'IRL'\n",
      "Geomatcher: Used 'IT' for 'ITA'\n",
      "Geomatcher: Used 'LT' for 'LTU'\n",
      "Geomatcher: Used 'LU' for 'LUX'\n",
      "Geomatcher: Used 'LV' for 'LVA'\n",
      "Geomatcher: Used 'MT' for 'MLT'\n",
      "Geomatcher: Used 'NL' for 'NLD'\n",
      "Geomatcher: Used 'PL' for 'POL'\n",
      "Geomatcher: Used 'PT' for 'PRT'\n",
      "Geomatcher: Used 'RO' for 'ROU'\n",
      "Geomatcher: Used 'SK' for 'SVK'\n",
      "Geomatcher: Used 'SI' for 'SVN'\n",
      "Geomatcher: Used 'SE' for 'SWE'\n",
      "Geomatcher: Used 'IN' for 'IND'\n",
      "Geomatcher: Used 'JP' for 'JPN'\n",
      "Geomatcher: Used 'AW' for 'ABW'\n",
      "Geomatcher: Used 'AI' for 'AIA'\n",
      "Geomatcher: Used 'AR' for 'ARG'\n",
      "Geomatcher: Used 'AQ' for 'ATA'\n",
      "Geomatcher: Used 'AG' for 'ATG'\n",
      "Geomatcher: Used 'BQ' for 'BES'\n",
      "Geomatcher: Used 'BS' for 'BHS'\n",
      "Geomatcher: Used 'BZ' for 'BLZ'\n",
      "Geomatcher: Used 'BM' for 'BMU'\n",
      "Geomatcher: Used 'BO' for 'BOL'\n",
      "Geomatcher: Used 'BR' for 'BRA'\n",
      "Geomatcher: Used 'BB' for 'BRB'\n",
      "Geomatcher: Used 'BV' for 'BVT'\n",
      "Geomatcher: Used 'CL' for 'CHL'\n",
      "Geomatcher: Used 'CO' for 'COL'\n",
      "Geomatcher: Used 'CR' for 'CRI'\n",
      "Geomatcher: Used 'CU' for 'CUB'\n",
      "Geomatcher: Used 'CW' for 'CUW'\n",
      "Geomatcher: Used 'KY' for 'CYM'\n",
      "Geomatcher: Used 'DM' for 'DMA'\n",
      "Geomatcher: Used 'DO' for 'DOM'\n",
      "Geomatcher: Used 'EC' for 'ECU'\n",
      "Geomatcher: Used 'FK' for 'FLK'\n",
      "Geomatcher: Used 'GP' for 'GLP'\n",
      "Geomatcher: Used 'GD' for 'GRD'\n",
      "Geomatcher: Used 'GT' for 'GTM'\n",
      "Geomatcher: Used 'GF' for 'GUF'\n",
      "Geomatcher: Used 'GY' for 'GUY'\n",
      "Geomatcher: Used 'HN' for 'HND'\n",
      "Geomatcher: Used 'HT' for 'HTI'\n",
      "Geomatcher: Used 'JM' for 'JAM'\n",
      "Geomatcher: Used 'KN' for 'KNA'\n",
      "Geomatcher: Used 'LC' for 'LCA'\n",
      "Geomatcher: Used 'MX' for 'MEX'\n",
      "Geomatcher: Used 'MS' for 'MSR'\n",
      "Geomatcher: Used 'MQ' for 'MTQ'\n",
      "Geomatcher: Used 'NI' for 'NIC'\n",
      "Geomatcher: Used 'PA' for 'PAN'\n",
      "Geomatcher: Used 'PE' for 'PER'\n",
      "Geomatcher: Used 'PR' for 'PRI'\n",
      "Geomatcher: Used 'PY' for 'PRY'\n",
      "Geomatcher: Used 'GS' for 'SGS'\n",
      "Geomatcher: Used 'SV' for 'SLV'\n",
      "Geomatcher: Used 'SR' for 'SUR'\n",
      "Geomatcher: Used 'SX' for 'SXM'\n",
      "Geomatcher: Used 'TC' for 'TCA'\n",
      "Geomatcher: Used 'TT' for 'TTO'\n",
      "Geomatcher: Used 'UY' for 'URY'\n",
      "Geomatcher: Used 'VC' for 'VCT'\n",
      "Geomatcher: Used 'VE' for 'VEN'\n",
      "Geomatcher: Used 'VG' for 'VGB'\n",
      "Geomatcher: Used 'VI' for 'VIR'\n",
      "Geomatcher: Used 'AE' for 'ARE'\n",
      "Geomatcher: Used 'BH' for 'BHR'\n",
      "Geomatcher: Used 'DZ' for 'DZA'\n",
      "Geomatcher: Used 'EG' for 'EGY'\n",
      "Geomatcher: Used 'EH' for 'ESH'\n",
      "Geomatcher: Used 'IR' for 'IRN'\n",
      "Geomatcher: Used 'IQ' for 'IRQ'\n",
      "Geomatcher: Used 'IL' for 'ISR'\n",
      "Geomatcher: Used 'JO' for 'JOR'\n",
      "Geomatcher: Used 'KW' for 'KWT'\n",
      "Geomatcher: Used 'LB' for 'LBN'\n",
      "Geomatcher: Used 'LY' for 'LBY'\n",
      "Geomatcher: Used 'MA' for 'MAR'\n",
      "Geomatcher: Used 'OM' for 'OMN'\n",
      "Geomatcher: Used 'PS' for 'PSE'\n",
      "Geomatcher: Used 'QA' for 'QAT'\n",
      "Geomatcher: Used 'SA' for 'SAU'\n",
      "Geomatcher: Used 'SD' for 'SDN'\n",
      "Geomatcher: Used 'SY' for 'SYR'\n",
      "Geomatcher: Used 'TN' for 'TUN'\n",
      "Geomatcher: Used 'YE' for 'YEM'\n",
      "Geomatcher: Used 'AL' for 'ALB'\n",
      "Geomatcher: Used 'AD' for 'AND'\n",
      "Geomatcher: Used 'BA' for 'BIH'\n",
      "Geomatcher: Used 'CH' for 'CHE'\n",
      "Geomatcher: Used 'GL' for 'GRL'\n",
      "Geomatcher: Used 'IS' for 'ISL'\n",
      "Geomatcher: Used 'LI' for 'LIE'\n",
      "Geomatcher: Used 'MC' for 'MCO'\n",
      "Geomatcher: Used 'MK' for 'MKD'\n",
      "Geomatcher: Used 'ME' for 'MNE'\n",
      "Geomatcher: Used 'NO' for 'NOR'\n",
      "Geomatcher: Used 'SJ' for 'SJM'\n",
      "Geomatcher: Used 'SM' for 'SMR'\n",
      "Geomatcher: Used 'RS' for 'SRB'\n",
      "Geomatcher: Used 'TR' for 'TUR'\n",
      "Geomatcher: Used 'VA' for 'VAT'\n",
      "Geomatcher: Used 'AF' for 'AFG'\n",
      "Geomatcher: Used 'AS' for 'ASM'\n",
      "Geomatcher: Used 'TF' for 'ATF'\n",
      "Geomatcher: Used 'BD' for 'BGD'\n",
      "Geomatcher: Used 'BN' for 'BRN'\n",
      "Geomatcher: Used 'BT' for 'BTN'\n",
      "Geomatcher: Used 'CK' for 'COK'\n",
      "Geomatcher: Used 'FJ' for 'FJI'\n",
      "Geomatcher: Used 'FM' for 'FSM'\n",
      "Geomatcher: Used 'GU' for 'GUM'\n",
      "Geomatcher: Used 'ID' for 'IDN'\n",
      "Geomatcher: Used 'IO' for 'IOT'\n",
      "Geomatcher: Used 'KH' for 'KHM'\n",
      "Geomatcher: Used 'KI' for 'KIR'\n",
      "Geomatcher: Used 'KR' for 'KOR'\n",
      "Geomatcher: Used 'LA' for 'LAO'\n",
      "Geomatcher: Used 'LK' for 'LKA'\n",
      "Geomatcher: Used 'MV' for 'MDV'\n",
      "Geomatcher: Used 'MH' for 'MHL'\n",
      "Geomatcher: Used 'MM' for 'MMR'\n",
      "Geomatcher: Used 'MN' for 'MNG'\n",
      "Geomatcher: Used 'MP' for 'MNP'\n",
      "Geomatcher: Used 'MY' for 'MYS'\n",
      "Geomatcher: Used 'NC' for 'NCL'\n",
      "Geomatcher: Used 'NF' for 'NFK'\n",
      "Geomatcher: Used 'NU' for 'NIU'\n",
      "Geomatcher: Used 'NP' for 'NPL'\n",
      "Geomatcher: Used 'NR' for 'NRU'\n",
      "Geomatcher: Used 'PK' for 'PAK'\n",
      "Geomatcher: Used 'PN' for 'PCN'\n",
      "Geomatcher: Used 'PH' for 'PHL'\n",
      "Geomatcher: Used 'PW' for 'PLW'\n",
      "Geomatcher: Used 'PG' for 'PNG'\n",
      "Geomatcher: Used 'KP' for 'PRK'\n",
      "Geomatcher: Used 'PF' for 'PYF'\n",
      "Geomatcher: Used 'SG' for 'SGP'\n",
      "Geomatcher: Used 'SB' for 'SLB'\n",
      "Geomatcher: Used 'TH' for 'THA'\n",
      "Geomatcher: Used 'TK' for 'TKL'\n",
      "Geomatcher: Used 'TL' for 'TLS'\n",
      "Geomatcher: Used 'TO' for 'TON'\n",
      "Geomatcher: Used 'TV' for 'TUV'\n",
      "Geomatcher: Used 'UM' for 'UMI'\n",
      "Geomatcher: Used 'VN' for 'VNM'\n",
      "Geomatcher: Used 'VU' for 'VUT'\n",
      "Geomatcher: Used 'WF' for 'WLF'\n",
      "Geomatcher: Used 'WS' for 'WSM'\n",
      "Geomatcher: Used 'AM' for 'ARM'\n",
      "Geomatcher: Used 'AZ' for 'AZE'\n",
      "Geomatcher: Used 'BY' for 'BLR'\n",
      "Geomatcher: Used 'GE' for 'GEO'\n",
      "Geomatcher: Used 'KZ' for 'KAZ'\n",
      "Geomatcher: Used 'KG' for 'KGZ'\n",
      "Geomatcher: Used 'MD' for 'MDA'\n",
      "Geomatcher: Used 'RU' for 'RUS'\n",
      "Geomatcher: Used 'TJ' for 'TJK'\n",
      "Geomatcher: Used 'TM' for 'TKM'\n",
      "Geomatcher: Used 'UA' for 'UKR'\n",
      "Geomatcher: Used 'UZ' for 'UZB'\n",
      "Geomatcher: Used 'AO' for 'AGO'\n",
      "Geomatcher: Used 'BI' for 'BDI'\n",
      "Geomatcher: Used 'BJ' for 'BEN'\n",
      "Geomatcher: Used 'BF' for 'BFA'\n",
      "Geomatcher: Used 'BW' for 'BWA'\n",
      "Geomatcher: Used 'CF' for 'CAF'\n",
      "Geomatcher: Used 'CI' for 'CIV'\n",
      "Geomatcher: Used 'CM' for 'CMR'\n",
      "Geomatcher: Used 'CD' for 'COD'\n",
      "Geomatcher: Used 'CG' for 'COG'\n",
      "Geomatcher: Used 'KM' for 'COM'\n",
      "Geomatcher: Used 'CV' for 'CPV'\n",
      "Geomatcher: Used 'DJ' for 'DJI'\n",
      "Geomatcher: Used 'ER' for 'ERI'\n",
      "Geomatcher: Used 'ET' for 'ETH'\n",
      "Geomatcher: Used 'GA' for 'GAB'\n",
      "Geomatcher: Used 'GH' for 'GHA'\n",
      "Geomatcher: Used 'GN' for 'GIN'\n",
      "Geomatcher: Used 'GM' for 'GMB'\n",
      "Geomatcher: Used 'GW' for 'GNB'\n",
      "Geomatcher: Used 'GQ' for 'GNQ'\n",
      "Geomatcher: Used 'KE' for 'KEN'\n",
      "Geomatcher: Used 'LR' for 'LBR'\n",
      "Geomatcher: Used 'LS' for 'LSO'\n",
      "Geomatcher: Used 'MG' for 'MDG'\n",
      "Geomatcher: Used 'ML' for 'MLI'\n",
      "Geomatcher: Used 'MZ' for 'MOZ'\n",
      "Geomatcher: Used 'MR' for 'MRT'\n",
      "Geomatcher: Used 'MU' for 'MUS'\n",
      "Geomatcher: Used 'MW' for 'MWI'\n",
      "Geomatcher: Used 'YT' for 'MYT'\n",
      "Geomatcher: Used 'NA' for 'NAM'\n",
      "Geomatcher: Used 'NE' for 'NER'\n",
      "Geomatcher: Used 'NG' for 'NGA'\n",
      "Geomatcher: Used 'RE' for 'REU'\n",
      "Geomatcher: Used 'RW' for 'RWA'\n",
      "Geomatcher: Used 'SN' for 'SEN'\n",
      "Geomatcher: Used 'SH' for 'SHN'\n",
      "Geomatcher: Used 'SL' for 'SLE'\n",
      "Geomatcher: Used 'SO' for 'SOM'\n",
      "Geomatcher: Used 'SS' for 'SSD'\n",
      "Geomatcher: Used 'ST' for 'STP'\n",
      "Geomatcher: Used 'SZ' for 'SWZ'\n",
      "Geomatcher: Used 'SC' for 'SYC'\n",
      "Geomatcher: Used 'TD' for 'TCD'\n",
      "Geomatcher: Used 'TG' for 'TGO'\n",
      "Geomatcher: Used 'TZ' for 'TZA'\n",
      "Geomatcher: Used 'UG' for 'UGA'\n",
      "Geomatcher: Used 'ZA' for 'ZAF'\n",
      "Geomatcher: Used 'ZM' for 'ZMB'\n",
      "Geomatcher: Used 'ZW' for 'ZWE'\n",
      "Geomatcher: Used 'US' for 'USA'\n"
     ]
    }
   ],
   "source": [
    "def get_remind_geomatcher():\n",
    "    \"\"\"Return geomatcher object which includes REMIND regions.\"\"\"\n",
    "\n",
    "    regionmapping = pd.read_csv(\"../data/regionmappingH12.csv\", sep=\";\")    \n",
    "    iso_2_rmnd = regionmapping.set_index(\"CountryCode\").to_dict()[\"RegionCode\"]\n",
    "    rmnd_2_iso = regionmapping.groupby(\"RegionCode\")[\"CountryCode\"].apply(list).to_dict()\n",
    "\n",
    "    geomatcher = Geomatcher()\n",
    "\n",
    "    # cc (cocos islands) seem to be not there, skipping\n",
    "    # list(geomatcher['CX'])[:10]\n",
    "    not_found = [\"CCK\", \"CXR\", 'GGY', 'JEY', 'BLM', 'MAF']\n",
    "    rmnd_2_iso_fix = {rmnd: [iso for iso in rmnd_2_iso[rmnd] if iso not in not_found] for rmnd in rmnd_2_iso}\n",
    "    #_rmnd_2_iso2_fix = {rmnd: [iso for iso in _rmnd_2_iso2[rmnd] if iso != \"CC\"] for rmnd in _rmnd_2_iso2}\n",
    "\n",
    "    geomatcher.add_definitions(rmnd_2_iso_fix, \"REMIND\")\n",
    "    return geomatcher\n",
    "\n",
    "if [x for x in geomatcher if 'REMIND' in x] != [('REMIND', 'CAZ'),\n",
    "                                                ('REMIND', 'CHA'),\n",
    "                                                ('REMIND', 'EUR'),\n",
    "                                                ('REMIND', 'IND'),\n",
    "                                                ('REMIND', 'JPN'),\n",
    "                                                ('REMIND', 'LAM'),\n",
    "                                                ('REMIND', 'MEA'),\n",
    "                                                ('REMIND', 'NEU'),\n",
    "                                                ('REMIND', 'OAS'),\n",
    "                                                ('REMIND', 'REF'),\n",
    "                                                ('REMIND', 'SSA'),\n",
    "                                                ('REMIND', 'USA')]:\n",
    "    geomatcher = get_remind_geomatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecoinvent_to_remind_locations(loc):\n",
    "    if loc== 'RoW':\n",
    "        loc='GLO'\n",
    "    \n",
    "    if loc in fix_names.keys():\n",
    "        loc = fix_names[loc]\n",
    "        \n",
    "    if loc == 'IAI Area, Russia & RER w/o EU27 & EFTA':\n",
    "        loc = 'RU'\n",
    "        \n",
    "    remind_loc = [r[1] for r in geomatcher.intersects(loc) if r[0]=='REMIND']\n",
    "    \n",
    "    ei_35_new_locs = {'XK':['NEU']}\n",
    "    \n",
    "    if not remind_loc:\n",
    "        if loc in ei_35_new_locs:\n",
    "            remind_loc =  ei_35_new_locs[loc]\n",
    "        else: \n",
    "            print('No location found for: ' + loc)\n",
    "            return None\n",
    "    return remind_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Remind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remind_data(scenario_name):\n",
    "    #This file reads the REMIND csv result file and returns a dataframe containing all the information\n",
    "    file_name = os.path.join(\"../data/Remind output files\", scenario_name+ \".mif\")           \n",
    "    df = pd.read_csv(file_name,sep=';', index_col = ['Region', 'Variable', 'Unit']).drop(columns = ['Model', 'Scenario', 'Unnamed: 24'])\n",
    "    df.columns =df.columns.astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documenting changes to ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exchange_amounts(ds, technosphere_filters=None, biosphere_filters=None):\n",
    "    result={}\n",
    "    for exc in technosphere(ds, *(technosphere_filters or [])):\n",
    "        result[(exc['name'], exc['location'])]=exc['amount']\n",
    "    for exc in biosphere(ds, *(biosphere_filters or [])):\n",
    "        result[(exc['name'], exc['categories'])]=exc['amount']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify electricity markets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import remind electricity markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "remind_electricity_market_labels = {\n",
    "\n",
    " 'Biomass CHP': 'SE|Electricity|Biomass|CHP|w/o CCS',\n",
    " 'Biomass IGCC CCS': 'SE|Electricity|Biomass|IGCCC|w/ CCS',\n",
    " 'Biomass IGCC': 'SE|Electricity|Biomass|IGCC|w/o CCS',\n",
    "\n",
    " 'Coal PC': 'SE|Electricity|Coal|PC|w/o CCS',\n",
    " 'Coal IGCC': 'SE|Electricity|Coal|IGCC|w/o CCS',\n",
    " 'Coal PC CCS': 'SE|Electricity|Coal|PCC|w/ CCS',\n",
    " 'Coal IGCC CCS': 'SE|Electricity|Coal|IGCCC|w/ CCS',\n",
    " 'Coal CHP':'SE|Electricity|Coal|CHP|w/o CCS',\n",
    "\n",
    "'Gas OC': 'SE|Electricity|Gas|GT',\n",
    "'Gas CC':'SE|Electricity|Gas|CC|w/o CCS',\n",
    "'Gas CHP': 'SE|Electricity|Gas|CHP|w/o CCS',\n",
    "'Gas CCS':  'SE|Electricity|Gas|w/ CCS',\n",
    "    \n",
    " 'Geothermal': 'SE|Electricity|Geothermal',\n",
    "    \n",
    " 'Hydro': 'SE|Electricity|Hydro',\n",
    "    \n",
    " 'Hydrogen': 'SE|Electricity|Hydrogen',\n",
    "    \n",
    " 'Nuclear': 'SE|Electricity|Nuclear',\n",
    "    \n",
    " 'Oil': 'SE|Electricity|Oil|w/o CCS',\n",
    "    \n",
    " 'Solar CSP': 'SE|Electricity|Solar|CSP',\n",
    " 'Solar PV': 'SE|Electricity|Solar|PV',\n",
    "    \n",
    " 'Wind': 'SE|Electricity|Wind',\n",
    "}\n",
    "\n",
    "rename_remind_electricity_market_labels = {v:k for k, v in remind_electricity_market_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remind_markets(remind_data, year, drop_hydrogen=True):\n",
    "    if year < 2005 or year >2150:\n",
    "        print('year not valid, must be between 2005 and 2150')\n",
    "        return\n",
    "    \n",
    "    elif year in remind_data.columns:\n",
    "        result =  remind_data.unstack(level=0)[year].loc[list(remind_electricity_market_labels.values())].reset_index(level=1, drop=True).rename(index = rename_remind_electricity_market_labels).divide(\n",
    "            remind_data.unstack(level=0)[year].loc[list(remind_electricity_market_labels.values())].sum(axis=0)).drop('World', axis=1)\n",
    "\n",
    "    else: \n",
    "        temp = remind_data.unstack(level=0).loc[list(remind_electricity_market_labels.values())].reset_index(level=1, drop=True).rename(index = rename_remind_electricity_market_labels).stack(level=1).T\n",
    "        new = pd.DataFrame(index = temp.columns,columns = [year],  data = np.nan).T\n",
    "    \n",
    "        result =  pd.concat([temp, new]).sort_index().interpolate(method = 'values').loc[year].unstack(level=1)\n",
    "        \n",
    "    if drop_hydrogen == False:\n",
    "        return result\n",
    "    else: \n",
    "        print('Excluding hydrogen from electricity markets.\\nHydrogen had a maximum share of '+ str(round(result.loc['Hydrogen'].max() * 100, 2)) + ' %')\n",
    "        return result.drop('Hydrogen', axis = 0).divide(result.drop('Hydrogen', axis = 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define technology matching between remind and ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_electricity_generating_technologies={\n",
    "\n",
    "    #From Carma project\n",
    "    'Biomass IGCC CCS':['Electricity, from CC plant, 100% SNG, truck 25km, post, pipeline 200km, storage 1000m/2025',\n",
    "                    'Electricity, at wood burning power plant 20 MW, truck 25km, post, pipeline 200km, storage 1000m/2025',\n",
    "                    'Electricity, at BIGCC power plant 450MW, pre, pipeline 200km, storage 1000m/2025'],\n",
    "    \n",
    "    #From Carma project\n",
    "    'Biomass IGCC': ['Electricity, at BIGCC power plant 450MW, no CCS/2025'],\n",
    "    \n",
    "\n",
    "    #From Carma project\n",
    "    'Coal IGCC':['Electricity, at power plant/hard coal, IGCC, no CCS/2025', \n",
    "                'Electricity, at power plant/lignite, IGCC, no CCS/2025'],\n",
    "    \n",
    "    'Coal IGCC CCS':['Electricity, at power plant/hard coal, pre, pipeline 200km, storage 1000m/2025',\n",
    "                      'Electricity, at power plant/lignite, pre, pipeline 200km, storage 1000m/2025',],\n",
    "   \n",
    "    #From Carma project\n",
    "     'Coal PC CCS':[ 'Electricity, at power plant/hard coal, post, pipeline 200km, storage 1000m/2025',\n",
    "                 'Electricity, at power plant/lignite, post, pipeline 200km, storage 1000m/2025'], \n",
    "\n",
    "    #From Carma project\n",
    "    'Gas CCS':['Electricity, at power plant/natural gas, pre, pipeline 200km, storage 1000m/2025',\n",
    "                        'Electricity, at power plant/natural gas, post, pipeline 200km, storage 1000m/2025'],\n",
    "    \n",
    "    # only Biomass CHP available\n",
    "    'Biomass CHP':['heat and power co-generation, wood chips, 6667 kW, state-of-the-art 2014', \n",
    "                    'heat and power co-generation, wood chips, 6667 kW',\n",
    "                    'heat and power co-generation, biogas, gas engine'],\n",
    "    \n",
    "    'Coal PC':['electricity production, hard coal',\n",
    "                'electricity production, lignite',\n",
    "              'electricity production, hard coal, conventional',\n",
    "              'electricity production, hard coal, supercritical'],\n",
    "                \n",
    "    'Coal CHP': ['heat and power co-generation, hard coal',\n",
    "                'heat and power co-generation, lignite'],\n",
    "    \n",
    "    \n",
    "    'Gas OC':['electricity production, natural gas, conventional power plant'],\n",
    "            \n",
    "    'Gas CC': ['electricity production, natural gas, combined cycle power plant'],    \n",
    "     \n",
    "    'Gas CHP': ['heat and power co-generation, natural gas, combined cycle power plant, 400MW electrical',\n",
    "            'heat and power co-generation, natural gas, conventional power plant, 100MW electrical'],\n",
    "            \n",
    "    'Geothermal':['electricity production, deep geothermal'],\n",
    "    \n",
    "    'Hydro':['electricity production, hydro, reservoir, alpine region',\n",
    "            'electricity production, hydro, reservoir, non-alpine region',\n",
    "            'electricity production, hydro, reservoir, tropical region',\n",
    "            'electricity production, hydro, run-of-river'],\n",
    "    \n",
    "    'Hydrogen':[],\n",
    "    \n",
    "    'Nuclear':['electricity production, nuclear, boiling water reactor',\n",
    "                'electricity production, nuclear, pressure water reactor, heavy water moderated',\n",
    "                'electricity production, nuclear, pressure water reactor'],\n",
    "    \n",
    "    'Oil':['electricity production, oil',\n",
    "          'heat and power co-generation, oil'],\n",
    "    \n",
    "    'Solar CSP': ['electricity production, solar thermal parabolic trough, 50 MW', \n",
    "               'electricity production, solar tower power plant, 20 MW'],\n",
    "    \n",
    "    'Solar PV':['electricity production, photovoltaic, 3kWp slanted-roof installation, multi-Si, panel, mounted',\n",
    "                    'electricity production, photovoltaic, 3kWp slanted-roof installation, single-Si, panel, mounted',\n",
    "                    'electricity production, photovoltaic, 570kWp open ground installation, multi-Si'], \n",
    "    \n",
    "    'Wind':['electricity production, wind, <1MW turbine, onshore',\n",
    "            'electricity production, wind, 1-3MW turbine, onshore',\n",
    "            'electricity production, wind, >3MW turbine, onshore',\n",
    "            'electricity production, wind, 1-3MW turbine, offshore']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for modifying ecoinvent electricity markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_market_filter_high_voltage= [contains('name', 'market for electricity, high voltage'),\n",
    "                                doesnt_contain_any('name', ['aluminium industry','internal use in coal mining'])]\n",
    "    \n",
    "electricity_market_filter_medium_voltage= [contains('name', 'market for electricity, medium voltage'),\n",
    "                                doesnt_contain_any('name', ['aluminium industry','electricity, from municipal waste incineration'])]\n",
    "    \n",
    "electricity_market_filter_low_voltage= [contains('name', 'market for electricity, low voltage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_electricity_inputs_from_market(ds):\n",
    "    #This function reads through an electricity market dataset and deletes all electricity inputs that are not own consumption. \n",
    "    ds['exchanges'] = [exc for exc in get_many(ds['exchanges'], *[either(*[exclude(contains('unit', 'kilowatt hour')),\n",
    "                                                                           contains('name', 'market for electricity, high voltage'),\n",
    "                                                                           contains('name', 'market for electricity, medium voltage'),\n",
    "                                                                           contains('name', 'market for electricity, low voltage'),\n",
    "                                                                           contains('name', 'electricity voltage transformation')])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_average_mix(df):\n",
    "    #This function considers that there might be several remind regions that match the ecoinvent region. This function returns the average mix across all regions.\n",
    "    #note that this function doesn't do a weighted average based on electricity production, but rather treats all regions equally.\n",
    "    return df.mean(axis=1).divide(df.mean(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ecoinvent_electricity_datasets_in_same_ecoinvent_location(tech, location, db):\n",
    "    #first try ecoinvent location code:\n",
    "    try: return [x for x in get_many(db, *[either(*[equals('name', name) for name in available_electricity_generating_technologies[tech]]), \n",
    "                                            equals('location', location), equals('unit', 'kilowatt hour')])]\n",
    "    #otherwise try remind location code (for new datasets)\n",
    "    except:\n",
    "        try: return [x for x in get_many(db, *[either(*[equals('name', name) for name in available_electricity_generating_technologies[tech]]), \n",
    "                                            equals('location', ecoinvent_to_remind_locations(location)), equals('unit', 'kilowatt hour')])]\n",
    "        except: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_other_ecoinvent_regions_in_remind_region(loc):\n",
    "    if loc== 'RoW':\n",
    "        loc='GLO'\n",
    "    \n",
    "    if loc in fix_names:\n",
    "        loc = fix_names[loc]\n",
    "    \n",
    "    remind_regions = [r for r in geomatcher.intersects(loc) if r[0]=='REMIND']\n",
    "\n",
    "    temp = []\n",
    "    for remind_region in remind_regions:\n",
    "        temp.extend([r for r in geomatcher.contained(remind_region)])\n",
    "\n",
    "    result = []\n",
    "    for temp in temp:\n",
    "        if type(temp) ==tuple:\n",
    "            result.append(temp[1])\n",
    "        else: result.append(temp)\n",
    "    return set(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ecoinvent_electricity_datasets_in_remind_location(tech, location, db):\n",
    "    try: return [x for x in get_many(db, *[either(*[equals('name', name) for name in available_electricity_generating_technologies[tech]]), \n",
    "                                            either(*[equals('location', loc) for loc in find_other_ecoinvent_regions_in_remind_region(location)]),\n",
    "                                        equals('unit', 'kilowatt hour')\n",
    "                          ])]\n",
    "    except: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ecoinvent_electricity_datasets_in_all_locations(tech, db):\n",
    "       return [x for x in get_many(db, *[either(*[equals('name', name) for name in available_electricity_generating_technologies[tech]]),equals('unit', 'kilowatt hour')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_datasets_to_electricity_market(ds, db, remind_electricity_market_df, year):\n",
    "    #This function adds new electricity datasets to a market based on remind results. We pass not only a dataset to modify, but also a pandas dataframe containing the new electricity mix information, and the db from which we should find the datasets\n",
    "    # find out which remind regions correspond to our dataset:\n",
    "        \n",
    "    remind_locations= ecoinvent_to_remind_locations(ds['location'])\n",
    "    \n",
    "    # here we find the mix of technologies in the new market and how much they contribute:\n",
    "    mix =  find_average_mix(remind_electricity_market_df[remind_locations]) #could be several remind locations - we just take the average\n",
    "   \n",
    "    \n",
    "    # here we find the datasets that will make up the mix for each technology\n",
    "    datasets={}\n",
    "    for i in mix.index:\n",
    "        if mix[i] !=0:\n",
    "            \n",
    "            #print('Next Technology: ',i) \n",
    "            \n",
    "            # We have imports defined for Switzerland. Let's do those first:\n",
    "            if i == 'Imports':\n",
    "                datasets[i] = [x for x in get_many(db, *[equals('name', 'market group for electricity, high voltage'), equals('location', 'ENTSO-E')])]\n",
    "            else:\n",
    "                # First try to find a dataset that is from that location (or remind region for new datasets):   \n",
    "                datasets[i] = find_ecoinvent_electricity_datasets_in_same_ecoinvent_location(i, ds['location'], db)\n",
    "                #print('First round: ',i, [(ds['name'], ds['location']) for ds in datasets[i]])\n",
    "            \n",
    "                #If this doesn't work, we try to take a dataset from another ecoinvent region within the same remind region                                    \n",
    "                if len(datasets[i]) == 0: \n",
    "                    datasets[i] = find_ecoinvent_electricity_datasets_in_remind_location(i, ds['location'], db)\n",
    "                    #print('Second round: ',i, [(ds['name'], ds['location']) for ds in datasets[i]])\n",
    "            \n",
    "                # If even this doesn't work, try taking a global datasets \n",
    "                if len(datasets[i]) == 0:  \n",
    "                    datasets[i] = find_ecoinvent_electricity_datasets_in_same_ecoinvent_location(i, 'GLO', db)\n",
    "                    #print('Third round: ',i, [(ds['name'], ds['location']) for ds in datasets[i]])\n",
    "                    \n",
    "                #if no global dataset available, we just take the average of all datasets we have:\n",
    "                if len(datasets[i]) ==0:  \n",
    "                    datasets[i] = find_ecoinvent_electricity_datasets_in_all_locations(i, db)\n",
    "                    #print('Fourth round: ',i, [(ds['name'], ds['location']) for ds in datasets[i]])\n",
    "                \n",
    "            #If we still can't find a dataset, we just take the global market group\n",
    "            if len(datasets[i]) ==0:\n",
    "                print('No match found for location: ', ds['location'], ' Technology: ', i,'. Taking global market group for electricity')\n",
    "                datasets[i] = [x for x in get_many(db, *[equals('name', 'market group for electricity, high voltage'), equals('location', 'GLO')])]\n",
    "                                            \n",
    "                            \n",
    "    # Now we add the new exchanges:\n",
    "    for i in mix.index:\n",
    "        if mix[i] !=0:\n",
    "            total_amount = mix[i]\n",
    "            amount= total_amount / len(datasets[i])\n",
    "            for dataset in datasets[i]:\n",
    "                ds['exchanges'].append({\n",
    "                'amount': amount,\n",
    "                'unit': dataset['unit'],    \n",
    "                'input': (dataset['database'], dataset['code']),\n",
    "                'type': 'technosphere',\n",
    "                'name': dataset['name'],\n",
    "                'location': dataset['location']                           \n",
    "                    })\n",
    "    \n",
    "    #confirm that exchanges sum to 1!\n",
    "    sum = np.sum([exc['amount'] for exc in technosphere(ds, *[equals('unit', 'kilowatt hour'), doesnt_contain_any('name', ['market for electricity, high voltage'])])])\n",
    "    if round(sum,4) != 1.00:  print(ds['location'], \" New exchanges don't add to one! something is wrong!\", sum )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_electricity_markets(db, year, remind_data):\n",
    "    \n",
    "    #import the remind market mix from the remind result files:\n",
    "    remind_electricity_market_df = get_remind_markets(remind_data, year, drop_hydrogen=True)\n",
    "\n",
    "    #Remove all electricity producers from markets:\n",
    "    db = empty_low_voltage_markets(db)\n",
    "    db = empty_medium_voltage_markets(db)\n",
    "    db = empty_high_voltage_markets(db) # This function isn't working as expected - it needs to delete imports as well.\n",
    "    \n",
    "    changes={}\n",
    "    #update high voltage markets:\n",
    "    for ds in get_many(db, *electricity_market_filter_high_voltage):\n",
    "        changes[ds['code']]={}\n",
    "        changes[ds['code']].update( {('meta data', x) : ds[x] for x in ['name','location']})\n",
    "        changes[ds['code']].update( {('original exchanges', k) :v for k,v in get_exchange_amounts(ds).items()})\n",
    "        delete_electricity_inputs_from_market(ds) # This function will delete the markets. Once Wurst is updated this can be deleted.\n",
    "        add_new_datasets_to_electricity_market(ds, db, remind_electricity_market_df, year)\n",
    "        changes[ds['code']].update( {('updated exchanges', k) :v for k,v in get_exchange_amounts(ds).items()})\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify Fossil Electricity Generation Technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get remind technology efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_remind_fossil_electricity_efficiency(remind_data, year, technology):\n",
    "\n",
    "    \n",
    "    fossil_electricity_efficiency_name_dict = {\n",
    "     'Biomass IGCC CCS':'Tech|Electricity|Biomass|IGCCC|w/ CCS|Efficiency', \n",
    "     'Biomass CHP':     'Tech|Electricity|Biomass|CHP|w/o CCS|Efficiency', \n",
    "     'Biomass IGCC':    'Tech|Electricity|Biomass|IGCC|w/o CCS|Efficiency',\n",
    "        \n",
    "    'Coal IGCC':'Tech|Electricity|Coal|IGCC|w/o CCS|Efficiency', \n",
    "     'Coal IGCC CCS':'Tech|Electricity|Coal|IGCCC|w/ CCS|Efficiency',\n",
    "     'Coal PC':'Tech|Electricity|Coal|PC|w/o CCS|Efficiency', \n",
    "     'Coal PC CCS':'Tech|Electricity|Coal|PCC|w/ CCS|Efficiency', \n",
    "     'Coal CHP': 'Tech|Electricity|Coal|CHP|w/o CCS|Efficiency',\n",
    "        \n",
    "    'Gas OC':'Tech|Electricity|Gas|GT|Efficiency', \n",
    "     'Gas CC':'Tech|Electricity|Gas|CC|w/o CCS|Efficiency',\n",
    "     'Gas CHP': 'Tech|Electricity|Gas|CHP|w/o CCS|Efficiency',\n",
    "     'Gas CCS':'Tech|Electricity|Gas|CCC|w/ CCS|Efficiency',\n",
    "     \n",
    "    'Oil':'Tech|Electricity|Oil|DOT|Efficiency',\n",
    "    }\n",
    "    \n",
    "    if year < 2005 or year > 2150:\n",
    "        print('year not valid, must be between 2005 and 2150')\n",
    "        return    \n",
    "    if technology not in fossil_electricity_efficiency_name_dict:\n",
    "        print(\"Technology name not recognized: {}\".format(technology))\n",
    "        return\n",
    "    \n",
    "    if fossil_electricity_efficiency_name_dict[technology] not in remind_data.index.levels[1]: \n",
    "        print('Technology efficiency not in REMIND output file: {}'.format(technology))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif year in remind_data.columns:\n",
    "        result =  remind_data.unstack(level=0).loc[fossil_electricity_efficiency_name_dict[technology]].stack(level = 0).reset_index(level = 0, drop=True).loc[year]\n",
    "    else: \n",
    "        temp = remind_data.unstack(level=0).loc[fossil_electricity_efficiency_name_dict[technology]].stack(level = 0).reset_index(level = 0, drop=True)\n",
    "        new = pd.DataFrame(index = temp.columns,columns = [year],  data = np.nan).T\n",
    "        result =  pd.concat([temp, new]).sort_index().interpolate(method = 'values').loc[year]\n",
    "    \n",
    "    if 0 in result.values:  \n",
    "        print('Warning: technology has regions with zero efficiency: {}'.format(technology))\n",
    "        print(result)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get ecoinvent efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ecoinvent_coal_efficiency(ds):\n",
    "    # Nearly all coal power plant datasets have the efficiency as a parameter. \n",
    "    # If this isn't available, we back calculate it using the amount of coal used and \n",
    "    # an average energy content of coal.\n",
    "    try: \n",
    "        return ds['parameters']['efficiency']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    #print('Efficiency parameter not found - calculating generic coal efficiency factor', ds['name'], ds['location'])\n",
    "    \n",
    "    fuel_sources = technosphere(ds, \n",
    "                                either(contains('name', 'hard coal'), contains('name', 'lignite')), \n",
    "                                doesnt_contain_any('name', ('ash','SOx')),\n",
    "                                equals('unit', 'kilogram'))\n",
    "    energy_in = 0 \n",
    "    for exc in fuel_sources:\n",
    "        if 'hard coal' in exc['name']: \n",
    "            energy_density = 20.1 / 3.6 #kWh/kg\n",
    "        elif 'lignite' in exc['name']: \n",
    "            energy_density = 9.9 / 3.6 # kWh/kg\n",
    "        else:\n",
    "            raise ValueError(\"Shouldn't happen because of filters!!!\")\n",
    "        energy_in += (exc['amount'] * energy_density)\n",
    "    ds['parameters']['efficiency'] = reference_product(ds)['amount'] / energy_in\n",
    "    #print(ds['parameters']['efficiency'])\n",
    "    return reference_product(ds)['amount'] / energy_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ecoinvent_gas_efficiency(ds):\n",
    "    \n",
    "    #Nearly all gas power plant datasets have the efficiency as a parameter. \n",
    "    #If this isn't available, we back calculate it using the amount of gas used and an average energy content of gas.\n",
    "    try: \n",
    "        return ds['parameters']['efficiency']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    #print('Efficiency parameter not found - calculating generic gas efficiency factor', ds['name'], ds['location'])\n",
    "    \n",
    "    fuel_sources = technosphere(ds,\n",
    "                                either(contains('name', 'natural gas, low pressure'), contains('name', 'natural gas, high pressure')), \n",
    "                                equals('unit', 'cubic meter'))\n",
    "    energy_in = 0 \n",
    "    for exc in fuel_sources:\n",
    "        #(based on energy density of natural gas input for global dataset 'electricity production, natural gas, conventional power plant')\n",
    "        if 'natural gas, high pressure' in exc['name']: \n",
    "            energy_density= 39 / 3.6 # kWh/m3 \n",
    "        \n",
    "        #(based on average energy density of high pressure gas, scaled by the mass difference listed between high pressure and low pressure gas in the dataset: \n",
    "        #natural gas pressure reduction from high to low pressure, RoW)\n",
    "        elif 'natural gas, low pressure' in exc['name']: energy_density= 39 * 0.84 / 3.6 #kWh/m3 \n",
    "        else:\n",
    "            raise ValueError(\"Shouldn't happen because of filters!!!\")\n",
    "        energy_in += (exc['amount'] * energy_density)\n",
    "    ds['parameters']['efficiency'] = reference_product(ds)['amount'] / energy_in\n",
    "    #print(ds['parameters']['efficiency'])\n",
    "    return reference_product(ds)['amount'] / energy_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ecoinvent_oil_efficiency(ds):\n",
    "    \n",
    "    #Nearly all oil power plant datasets have the efficiency as a parameter. If this isn't available, we use global average values to calculate it.\n",
    "    try: return ds['parameters']['efficiency_oil_country']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    #print('Efficiency parameter not found - calculating generic oil efficiency factor', ds['name'], ds['location'])\n",
    "    fuel_sources=[x for x in technosphere(ds, *[contains('name', 'heavy fuel oil'), \n",
    "                                    equals('unit', 'kilogram')]\n",
    "                                    )]\n",
    "    energy_in=0 \n",
    "    for exc in fuel_sources:\n",
    "        #(based on energy density of heavy oil input and efficiency parameter for dataset 'electricity production, oil, RoW')\n",
    "        energy_density= 38.5 / 3.6 # kWh/m3 \n",
    "        energy_in += (exc['amount'] * energy_density)\n",
    "    ds['parameters']['efficiency'] = reference_product(ds)['amount'] / energy_in\n",
    "    #print(ds['parameters']['efficiency'])\n",
    "    return reference_product(ds)['amount'] /energy_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ecoinvent_biomass_efficiency(ds):\n",
    "    #Nearly all power plant datasets have the efficiency as a parameter. If this isn't available, we excl.\n",
    "    try: return ds['parameters']['efficiency_electrical']\n",
    "    except: pass\n",
    "    \n",
    "    if ds['name'] == 'heat and power co-generation, biogas, gas engine, label-certified': \n",
    "        ds['parameters'] = {'efficiency_electrical': 0.32}\n",
    "        return ds['parameters']['efficiency_electrical']#in general comments for dataset\n",
    "    \n",
    "    elif ds['name'] == 'wood pellets, burned in stirling heat and power co-generation unit, 3kW electrical, future': \n",
    "        ds['parameters'] = {'efficiency_electrical': 0.23}\n",
    "        return ds['parameters']['efficiency_electrical'] #in comments for dataset  \n",
    "    \n",
    "    print(ds['name'], ds['location'],' Efficiency not found!')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_ecoinvent_efficiency_parameter(ds, scaling_factor):\n",
    "    parameters = ds['parameters']\n",
    "    possibles = ['efficiency', 'efficiency_oil_country', 'efficiency_electrical']\n",
    "\n",
    "    for key in possibles:\n",
    "        try: \n",
    "            parameters[key] /= scaling_factor\n",
    "            return\n",
    "        except KeyError:   \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find efficiency scaling factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_coal_efficiency_scaling_factor(ds, year, remind_efficiency, agg_func=np.average):\n",
    "    #input a coal electricity dataset and year. We look up the efficiency for this region and year from the remind model and return the scaling factor by which to multiply all efficiency dependent exchanges.\n",
    "    #If the ecoinvent region corresponds to multiple remind regions we simply average them.\n",
    "    ecoinvent_eff = find_ecoinvent_coal_efficiency(ds)\n",
    "    remind_locations= ecoinvent_to_remind_locations(ds['location'])\n",
    "    remind_eff = agg_func(remind_efficiency [remind_locations].values)/100 # we take an average of all applicable remind locations\n",
    "    return ecoinvent_eff / remind_eff\n",
    "\n",
    "def find_gas_efficiency_scaling_factor(ds, year, remind_efficiency, agg_func=np.average):\n",
    "    #input a gas electricity dataset and year. We look up the efficiency for this region and year from the remind model and return the scaling factor by which to multiply all efficiency dependent exchanges.\n",
    "    #If the ecoinvent region corresponds to multiple remind regions we simply average them.\n",
    "    ecoinvent_eff = find_ecoinvent_gas_efficiency(ds)\n",
    "    remind_locations= ecoinvent_to_remind_locations(ds['location'])\n",
    "    remind_eff = agg_func(remind_efficiency [remind_locations].values)/100 # we take an average of all applicable remind locations\n",
    "    return ecoinvent_eff / remind_eff\n",
    "\n",
    "def find_oil_efficiency_scaling_factor(ds, year, remind_efficiency, agg_func=np.average):\n",
    "    #input a oil electricity dataset and year. We look up the efficiency for this region and year from the remind model and return the scaling factor by which to multiply all efficiency dependent exchanges.\n",
    "    #If the ecoinvent region corresponds to multiple remind regions we simply average them.\n",
    "    ecoinvent_eff = find_ecoinvent_oil_efficiency(ds)\n",
    "    remind_locations= ecoinvent_to_remind_locations(ds['location'])\n",
    "    remind_eff = agg_func(remind_efficiency [remind_locations].values)/100 # we take an average of all applicable remind locations\n",
    "    return ecoinvent_eff / remind_eff\n",
    "\n",
    "def find_biomass_efficiency_scaling_factor(ds, year, remind_efficiency, agg_func=np.average):\n",
    "    #input an electricity dataset and year. We look up the efficiency for this region and year from the remind model and return the scaling factor by which to multiply all efficiency dependent exchanges.\n",
    "    #If the ecoinvent region corresponds to multiple remind regions we simply average them.\n",
    "    ecoinvent_eff = find_ecoinvent_biomass_efficiency(ds)\n",
    "    remind_locations= ecoinvent_to_remind_locations(ds['location'])\n",
    "    remind_eff = agg_func(remind_efficiency [remind_locations].values)/100 # we take an average of all applicable remind locations\n",
    "    return ecoinvent_eff / remind_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get remind emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emission_factors(scenario = \"SSP2\"):\n",
    "    file_name = os.path.join(\"../data\", \"GAINS emission factors.csv\")   \n",
    "    gains_emi = pd.read_csv(file_name, skiprows=4, \n",
    "                            names=[\"year\", \"region\", \"GAINS\", \"pollutant\", \"scenario\", \"factor\"])\n",
    "    gains_emi[\"unit\"] = \"Mt/TWa\"\n",
    "    gains_emi = gains_emi[gains_emi.scenario == scenario]\n",
    "\n",
    "    file_name = os.path.join(\"../data\", \"GAINStoREMINDtechmap.csv\")\n",
    "    sector_mapping = pd.read_csv(file_name).drop([\"noef\", \"elasticity\"], axis=1)\n",
    "    \n",
    "    return gains_emi.join(sector_mapping.set_index(\"GAINS\"), on=\"GAINS\").dropna().drop(['scenario', 'REMIND'], axis=1).set_index(['year', 'region','GAINS', 'pollutant'])['factor'].unstack(level = [0,1,3]) /8760 #kg / kWh\n",
    "\n",
    "\n",
    "# unfortunately, we currently don't have much resolution in these technologies, but it's better than nothing:\n",
    "emissions_lookup_dict = {\n",
    "    'Biomass IGCC CCS':'Power_Gen_Bio_Trad',\n",
    "    'Biomass IGCC': 'Power_Gen_Bio_Trad',\n",
    "    'Biomass CHP':'Power_Gen_Bio_Trad',\n",
    "    'Coal IGCC':'Power_Gen_Coal' ,\n",
    "    'Coal IGCC CCS':'Power_Gen_Coal' ,\n",
    "    'Coal PC':    'Power_Gen_Coal'     , \n",
    "    'Coal CHP': 'Power_Gen_Coal' ,\n",
    "    'Coal PC CCS':'Power_Gen_Coal' ,\n",
    "    'Gas CCS':'Power_Gen_NatGas',\n",
    "    'Gas OC':  'Power_Gen_NatGas'   , \n",
    "    'Gas CC':  'Power_Gen_NatGas',\n",
    "    'Gas CHP':'Power_Gen_NatGas',\n",
    "    'Oil': 'Power_Gen_LLF'}\n",
    "\n",
    "\n",
    "def get_remind_emissions(remind_emissions_factors, year, region, tech):\n",
    "    if year in remind_emissions_factors.columns.levels[0]: \n",
    "        result = remind_emissions_factors.loc[emissions_lookup_dict[tech]].unstack(level=[1,2])[region].loc[year]\n",
    "    else:    \n",
    "        temp = remind_emissions_factors.loc[emissions_lookup_dict[tech]].unstack(level=[1,2])[region]\n",
    "        new = pd.DataFrame(index = temp.columns,columns = [year],  data = np.nan).T\n",
    "        \n",
    "        result =  pd.concat([temp, new]).sort_index().interpolate(method = 'values').loc[year]\n",
    "        \n",
    "    if type(region) == list:\n",
    "        result = result.unstack(level=0)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify ecoinvent fossil electricity generation technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remind_air_pollutants ={ # for now we don't have any emissions data from remind, so we scale everything by efficiency.\n",
    "    'Sulfur dioxide': 'SO2', \n",
    "    'Carbon monoxide, fossil': 'CO', \n",
    "    'Nitrogen oxides': 'NOx',\n",
    "    'Ammonia': 'NH3',\n",
    "    'NMVOC, non-methane volatile organic compounds, unspecified origin': 'VOC',\n",
    "    #'BC',\n",
    "    #'OC',\n",
    "}   \n",
    "\n",
    "#define filter functions that decide which ecoinvent processes to modify\n",
    "no_al = [exclude(contains('name', 'aluminium industry'))]\n",
    "no_ccs = [exclude(contains('name', 'carbon capture and storage'))]\n",
    "no_markets = [exclude(contains('name', 'market'))]\n",
    "no_imports = [exclude(contains('name', 'import'))]\n",
    "generic_excludes = no_al + no_ccs + no_markets\n",
    "\n",
    "#there are some problems with the Wurst filter functions - we create a quick fix here:\n",
    "gas_open_cycle_electricity = [equals('name', 'electricity production, natural gas, conventional power plant')]\n",
    "biomass_chp_electricity = [either(contains('name', ' wood'), contains('name', 'bio')), equals('unit', 'kilowatt hour'), contains('name', 'heat and power co-generation') ]\n",
    "\n",
    "remind_mapping = {\n",
    "    'Coal PC': {  \n",
    "        'eff_func': find_coal_efficiency_scaling_factor,\n",
    "        'technology filters': coal_electricity + generic_excludes,\n",
    "        'technosphere excludes': [], # which technosphere exchanges to not change at all\n",
    "    },\n",
    "    'Coal CHP': {\n",
    "       'eff_func': find_coal_efficiency_scaling_factor,\n",
    "        'technology filters': coal_chp_electricity + generic_excludes,\n",
    "        'technosphere excludes': [],  # which technosphere exchanges to not change at all      \n",
    "    },\n",
    "    'Gas OC': {\n",
    "        'eff_func': find_gas_efficiency_scaling_factor,\n",
    "        'technology filters': gas_open_cycle_electricity + generic_excludes + no_imports,\n",
    "        'technosphere excludes': [],  # which technosphere exchanges to not change at all              \n",
    "    },\n",
    "    'Gas CC': {\n",
    "        'eff_func': find_gas_efficiency_scaling_factor,\n",
    "        'technology filters': gas_combined_cycle_electricity + generic_excludes + no_imports, \n",
    "        'technosphere excludes': [],  # which technosphere exchanges to not change at all              \n",
    "    },\n",
    "    'Gas CHP': {\n",
    "        'eff_func': find_gas_efficiency_scaling_factor,\n",
    "        'technology filters': gas_chp_electricity + generic_excludes + no_imports, \n",
    "        'technosphere excludes': [],    # which technosphere exchanges to not change at all            \n",
    "    },    \n",
    "    'Oil': {  \n",
    "        'eff_func': find_oil_efficiency_scaling_factor,\n",
    "        'technology filters': oil_open_cycle_electricity + generic_excludes+ [exclude(contains('name', 'nuclear'))],\n",
    "        'technosphere excludes': [],# which technosphere exchanges to not change at all\n",
    "    },  \n",
    "\n",
    "#    'Biomass ST': {  \n",
    "#        'eff_func': find_biomass_efficiency_scaling_factor,\n",
    "#        'technology filters': biomass_electricity + generic_excludes,\n",
    "#        'technosphere excludes': [],# which technosphere exchanges to not change at all\n",
    "#    }, \n",
    "    'Biomass CHP': {  \n",
    "        'eff_func': find_biomass_efficiency_scaling_factor,\n",
    "        'technology filters': biomass_chp_electricity + generic_excludes,\n",
    "        'technosphere excludes': [],# which technosphere exchanges to not change at all\n",
    "    }, \n",
    "#    'Biomass CC': {  \n",
    "#        'eff_func': find_biomass_efficiency_scaling_factor,\n",
    "#        'technology filters': biomass_combined_cycle_electricity + generic_excludes,\n",
    "#        'technosphere excludes': [],# which technosphere exchanges to not change at all\n",
    "#    }, \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_electricity_datasets_with_remind_data(db, remind_data, year, agg_func=np.average, update_efficiency = True, update_emissions = True):\n",
    "    \"\"\"    \n",
    "       This function modifies each ecoinvent coal, gas, oil and biomass dataset using data from the remind model. \n",
    "    \"\"\"\n",
    "    print(\"Don't forget that we aren't modifying PM emissions!\")\n",
    "    \n",
    "    changes ={}\n",
    "    \n",
    "    for remind_technology in remind_mapping:\n",
    "        print('Changing ', remind_technology)\n",
    "        md = remind_mapping[remind_technology]\n",
    "        remind_efficiency = get_remind_fossil_electricity_efficiency(remind_data, year, remind_technology)\n",
    "        remind_emissions_factors = get_emission_factors()\n",
    "\n",
    "        for ds in get_many(db, *md['technology filters']):\n",
    "            changes[ds['code']]={}\n",
    "            changes[ds['code']].update( {('meta data', x) : ds[x] for x in ['name','location']})\n",
    "            changes[ds['code']].update( {('meta data', 'remind technology') : remind_technology})\n",
    "            changes[ds['code']].update( {('original exchanges', k) :v for k,v in get_exchange_amounts(ds).items()})\n",
    "            if update_efficiency == True:\n",
    "                # Modify using remind efficiency values: \n",
    "                scaling_factor = md['eff_func'](ds, year, remind_efficiency, agg_func)\n",
    "                update_ecoinvent_efficiency_parameter(ds, scaling_factor)\n",
    "                change_exchanges_by_constant_factor(ds, scaling_factor, md['technosphere excludes'], \n",
    "                                                [doesnt_contain_any('name', remind_air_pollutants)])\n",
    "            \n",
    "            # we use this bit of code to explicitly rewrite the value for certain emissions.\n",
    "            if update_emissions == True: \n",
    "                # Modify using remind specific emissions data\n",
    "                remind_locations = ecoinvent_to_remind_locations(ds['location'])\n",
    "                remind_emissions = get_remind_emissions(remind_emissions_factors, year, remind_locations, remind_technology)\n",
    "                for exc in biosphere(ds, either(*[contains('name', x) for x in remind_air_pollutants])):\n",
    "                    \n",
    "                    flow = remind_air_pollutants[exc['name']]\n",
    "                    amount =  agg_func(remind_emissions.loc[flow].values)\n",
    "                        \n",
    "                    #if new amount isn't a number:\n",
    "                    if np.isnan(amount): \n",
    "                        print('Not a number! Setting exchange to zero' + ds['name'], exc['name'], ds['location'])\n",
    "                        rescale_exchange(exc, 0) \n",
    "                        \n",
    "                    #if old amound was zero:\n",
    "                    elif exc['amount'] ==0:\n",
    "                        exc['amount'] = 1 \n",
    "                        rescale_exchange(exc, amount / exc['amount'], remove_uncertainty = True)\n",
    "                        \n",
    "                    else: \n",
    "                        rescale_exchange(exc, amount / exc['amount'])\n",
    " \n",
    "            changes[ds['code']].update( {('updated exchanges', k) :v for k,v in get_exchange_amounts(ds).items()}) \n",
    "            \n",
    "        #check if exchange amounts are real numbers:\n",
    "            for k,v in get_exchange_amounts(ds).items():\n",
    "                if np.isnan(v): print(ds, k)\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying Carma datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carma_electricity_ds_name_dict = {  \n",
    " 'Electricity, at BIGCC power plant 450MW, no CCS/2025': 'Biomass IGCC',\n",
    "    \n",
    " 'Electricity, at BIGCC power plant 450MW, pre, pipeline 200km, storage 1000m/2025': 'Biomass IGCC CCS',\n",
    " 'Electricity, at wood burning power plant 20 MW, truck 25km, post, pipeline 200km, storage 1000m/2025': 'Biomass IGCC CCS',\n",
    " 'Electricity, from CC plant, 100% SNG, truck 25km, post, pipeline 200km, storage 1000m/2025': 'Biomass IGCC CCS',  \n",
    "\n",
    " 'Electricity, at power plant/hard coal, IGCC, no CCS/2025': 'Coal IGCC',\n",
    " 'Electricity, at power plant/lignite, IGCC, no CCS/2025': 'Coal IGCC',\n",
    " 'Electricity, at power plant/hard coal, pre, pipeline 200km, storage 1000m/2025': 'Coal IGCC CCS',\n",
    " 'Electricity, at power plant/lignite, pre, pipeline 200km, storage 1000m/2025': 'Coal IGCC CCS',\n",
    "    \n",
    " 'Electricity, at power plant/hard coal, post, pipeline 200km, storage 1000m/2025': 'Coal PC CCS',\n",
    " 'Electricity, at power plant/lignite, post, pipeline 200km, storage 1000m/2025': 'Coal PC CCS',\n",
    "    \n",
    " 'Electricity, at power plant/natural gas, post, pipeline 200km, storage 1000m/2025': 'Gas CCS',\n",
    " 'Electricity, at power plant/natural gas, pre, pipeline 200km, storage 1000m/2025': 'Gas CCS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_all_carma_electricity_datasets(db, remind_data, year, update_efficiency = True, update_emissions = True):\n",
    "    remind_emissions_factors = get_emission_factors()\n",
    "    changes ={}\n",
    "    \n",
    "    for name, remind_technology in carma_electricity_ds_name_dict.items():        \n",
    "        remind_efficiency = get_remind_fossil_electricity_efficiency(remind_data, year, remind_technology) / 100 # Convert from percent.\n",
    "\n",
    "        \n",
    "        for ds in get_many(db, equals('name', name)):\n",
    "            changes[ds['code']]={}\n",
    "            changes[ds['code']].update( {('meta data', x) : ds[x] for x in ['name','location']})\n",
    "            changes[ds['code']].update( {('meta data', 'remind technology') : remind_technology})\n",
    "            changes[ds['code']].update( {('original exchanges', k) :v for k,v in get_exchange_amounts(ds).items()}\n",
    "                                      )   \n",
    "            if update_efficiency: \n",
    "                if 'Electricity, at BIGCC power plant 450MW' in ds['name']: \n",
    "                    modify_carma_BIGCC_efficiency(ds, remind_efficiency)\n",
    "                else:\n",
    "                    modify_standard_carma_dataset_efficiency(ds, remind_efficiency)\n",
    "            if update_emissions:             \n",
    "                modify_carma_dataset_emissions(db, ds, remind_emissions_factors, year, remind_technology)\n",
    "    \n",
    "        changes[ds['code']].update( {('updated exchanges', k) :v for k,v in get_exchange_amounts(ds).items()})\n",
    "    \n",
    "    #The efficiency defined by image also includes the electricity consumed in the carbon capture process, so we have to set this exchange amount to zero:\n",
    "    if update_efficiency:\n",
    "        for ds in get_many(db, contains('name', 'CO2 capture')):\n",
    "            for exc in technosphere(ds, *[contains('name', 'Electricity'), equals('unit', 'kilowatt hour')]):\n",
    "                exc['amount'] = 0\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_carma_dataset_emissions(db, ds, remind_emissions_factors, year, remind_technology):\n",
    "    #The dataset passed to this function doesn't have the biosphere flows directly. Rather, it has an exchange (with unit MJ) that contains the biosphere flows per unit fuel input. \n",
    "\n",
    "    biosphere_mapping={'SO2':'Sulfur dioxide', \n",
    "                       'CO': 'Carbon monoxide, fossil', \n",
    "                       'NOx': 'Nitrogen oxides',\n",
    "                       } \n",
    "    \n",
    "    remind_locations = ecoinvent_to_remind_locations(ds['location'])\n",
    "    remind_emissions = get_remind_emissions(remind_emissions_factors, year, remind_locations, remind_technology)\n",
    "        \n",
    "    exc_dataset_names = [x['name'] for x in technosphere(ds, equals('unit', 'megajoule'))]\n",
    "    \n",
    "    for exc_dataset in get_many(db, *[either(*[equals('name', exc_dataset_name) for exc_dataset_name in exc_dataset_names])]):\n",
    "        \n",
    "        if len(list(biosphere(exc_dataset)))==0: \n",
    "            modify_carma_dataset_emissions(db, exc_dataset, remind_emissions_factors, year, remind_technology)\n",
    "            continue\n",
    "            \n",
    "        #Modify using IMAGE emissions data\n",
    "        for key, value in biosphere_mapping.items():\n",
    "            for exc in biosphere(exc_dataset, contains('name', value)):          \n",
    "                exc['amount'] = np.average(remind_emissions.loc[key][remind_locations])\n",
    "                if np.isnan(exc['amount']): \n",
    "                    print('Not a number! Setting exchange to zero' + ds['name'], exc['name'], ds['location'])\n",
    "                    exc['amount']=0\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_carma_BIGCC_efficiency(ds, remind_efficiency):\n",
    "    remind_locations = ecoinvent_to_remind_locations(ds['location'])\n",
    "    remind_efficiency = np.average(remind_efficiency[remind_locations])\n",
    "    \n",
    "    old_efficiency = 3.6/get_one(technosphere(ds), *[contains('name', 'Hydrogen, from steam reforming')])['amount'] \n",
    "\n",
    "    for exc in technosphere(ds):\n",
    "        exc['amount'] = exc['amount']*old_efficiency/remind_efficiency\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_standard_carma_dataset_efficiency(ds, remind_efficiency):\n",
    "    if 'Electricity, at BIGCC power plant 450MW' in ds['name']:\n",
    "        print(\"This function can't modify dataset: \",ds['name'], \"It's got a different format.\")\n",
    "        return\n",
    "    \n",
    "    remind_locations = ecoinvent_to_remind_locations(ds['location'])\n",
    "    remind_efficiency = np.average(remind_efficiency[remind_locations])\n",
    "    \n",
    "    #All other carma electricity datasets have a single exchange that is the combustion of a fuel in MJ. \n",
    "    #We can just scale this exchange and efficiency related changes will be done\n",
    "    \n",
    "    for exc in technosphere(ds):\n",
    "        exc['amount'] = 3.6/remind_efficiency\n",
    "   \n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
